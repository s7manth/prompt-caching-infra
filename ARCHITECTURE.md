# Architecture Overview

## System Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚
â”‚  (curl/app) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ POST /chat
       â”‚ {prompt: "..."}
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Cloudflare Worker (Edge Runtime)        â”‚
â”‚                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  1. Receive Request                    â”‚ â”‚
â”‚  â”‚     â†“                                  â”‚ â”‚
â”‚  â”‚  2. Generate Embedding                 â”‚ â”‚
â”‚  â”‚     (Workers AI: bge-base-en-v1.5)     â”‚ â”‚
â”‚  â”‚     â†“                                  â”‚ â”‚
â”‚  â”‚  3. Search Redis for Similar Vectors   â”‚ â”‚
â”‚  â”‚     â†“                                  â”‚ â”‚
â”‚  â”‚  4. Cache Hit?                         â”‚ â”‚
â”‚  â”‚     â”œâ”€ YES â†’ Return Cached (fast!)     â”‚ â”‚
â”‚  â”‚     â””â”€ NO â†’ Continue                   â”‚ â”‚
â”‚  â”‚            â†“                           â”‚ â”‚
â”‚  â”‚  5. Call Workers AI (LLM inference)    â”‚ â”‚
â”‚  â”‚     â†“                                  â”‚ â”‚
â”‚  â”‚  6. Cache Response in Redis            â”‚ â”‚
â”‚  â”‚     â†“                                  â”‚ â”‚
â”‚  â”‚  7. Return Response to Client          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                â”‚
         â”‚                â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚ Redis   â”‚      â”‚ KV Store â”‚
    â”‚ (Upstash)â”‚      â”‚ (Stats)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Components

### 1. Cloudflare Worker (`src/index.ts`)

- **Purpose**: Main entry point and request router
- **Endpoints**:
  - `POST /chat` - Submit prompts for caching/inference
  - `GET /stats` - View cache statistics
  - `GET /health` - Health check
- **Responsibilities**:
  - Request validation
  - Route handling
  - Response formatting
  - Statistics tracking

### 2. Prompt Cache (`src/cache.ts`)

- **Purpose**: High-level caching logic
- **Features**:
  - Embedding generation
  - Similarity search orchestration
  - Cache storage
  - ID generation
- **Key Method**: `findSimilarCache()` - Searches for semantically similar prompts

### 3. Redis Vector Store (`src/redis.ts`)

- **Purpose**: Low-level Redis operations
- **Features**:
  - REST API communication with Upstash
  - Vector storage using RedisJSON
  - Cosine similarity computation
  - Brute-force vector search
- **Storage Format**:
  ```json
  {
    "prompt": "original text",
    "embedding": [0.1, 0.2, ...],
    "response": "LLM output",
    "timestamp": 1234567890,
    "model": "@cf/meta/llama-2-7b-chat-int8"
  }
  ```

### 4. Workers AI

- **Embedding Model**: `@cf/baai/bge-base-en-v1.5`
  - Converts text â†’ 768-dimensional vector
  - Used for semantic similarity
- **LLM Model**: `@cf/meta/llama-2-7b-chat-int8` (default)
  - Generates responses for cache misses

### 5. Storage Layers

#### Redis (Upstash)

- **Purpose**: Vector embeddings + cached responses
- **Why Redis**: Fast key-value access, RedisJSON support
- **Format**: JSON documents with vector arrays

#### Cloudflare KV

- **Purpose**: Metadata (hit/miss counts)
- **Why KV**: Global edge distribution, simple counters

## Data Flow

### Cache Miss Flow (First Request)

```
1. Client â†’ Worker: "What is AI?"
2. Worker â†’ Workers AI: Generate embedding for "What is AI?"
3. Worker â†’ Redis: Search similar vectors (threshold: 0.85)
4. Redis â†’ Worker: No matches found
5. Worker â†’ Workers AI: Generate response for "What is AI?"
6. Workers AI â†’ Worker: "AI is artificial intelligence..."
7. Worker â†’ Redis: Store (prompt, embedding, response)
8. Worker â†’ Client: {response: "...", cached: false}
```

### Cache Hit Flow (Similar Request)

```
1. Client â†’ Worker: "Can you explain AI?"
2. Worker â†’ Workers AI: Generate embedding for "Can you explain AI?"
3. Worker â†’ Redis: Search similar vectors
4. Redis â†’ Worker: Found match! (similarity: 0.92)
5. Worker â†’ Client: {response: "...", cached: true, similarity: 0.92}
```

## Performance Characteristics

| Scenario   | Latency   | Cost                          |
| ---------- | --------- | ----------------------------- |
| Cache Miss | 2-5s      | Full LLM inference            |
| Cache Hit  | 200-500ms | Embedding only (~10x cheaper) |

## Similarity Threshold

- **Default**: 0.85 (85% similarity)
- **Range**: 0.0 to 1.0
- **Impact**:
  - **Higher** (0.9+): Stricter matching, fewer hits
  - **Lower** (0.7-0.8): More hits, less precise

## Scalability Considerations

### Current Implementation (1-Hour Build)

- âœ… Good for: Up to ~1,000 cached prompts
- âš ï¸ Limitation: Brute-force vector search (O(n))

### Production Optimizations

- Use Redis FT.SEARCH with HNSW indexes (O(log n))
- Implement cache eviction (TTL, LRU)
- Add multi-model support
- Implement request batching

## Security

### Current (v1.0)

- âŒ No authentication
- âœ… CORS enabled
- âœ… Input validation

### Recommended Additions

- API key authentication
- Rate limiting
- Request size limits
- IP allowlisting

## Cost Estimation

### Cloudflare Workers

- Free tier: 100,000 requests/day
- Paid: $0.50 per million requests

### Workers AI

- Free tier: 10,000 neurons/day
- Embeddings: ~5 neurons per request
- LLM inference: ~1,000+ neurons per request

### Redis (Upstash)

- Free tier: 10,000 commands/day
- Paid: Pay-as-you-go

### Example Savings

- 1,000 requests/day
- 70% cache hit rate
- **Cost reduction**: ~60% (embeddings vs. full inference)

## Extension Ideas

1. **Multi-model support**: Cache per model
2. **Streaming responses**: Server-sent events
3. **Analytics dashboard**: Visualize cache performance
4. **Smart eviction**: Remove old/unused entries
5. **Prompt preprocessing**: Normalize prompts before embedding
6. **Response post-processing**: Personalize cached responses

## File Structure

```
prompt-caching-infra/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts       # Main worker entry point
â”‚   â”œâ”€â”€ cache.ts       # Caching logic
â”‚   â”œâ”€â”€ redis.ts       # Redis operations
â”‚   â””â”€â”€ types.ts       # TypeScript types
â”œâ”€â”€ wrangler.toml      # Cloudflare config
â”œâ”€â”€ package.json       # Dependencies
â”œâ”€â”€ tsconfig.json      # TypeScript config
â”œâ”€â”€ README.md          # Full documentation
â”œâ”€â”€ QUICKSTART.md      # Setup guide
â”œâ”€â”€ ARCHITECTURE.md    # This file
â””â”€â”€ example-test.sh    # Testing script
```

## Tech Stack Summary

- **Runtime**: Cloudflare Workers (Edge)
- **Language**: TypeScript
- **LLM**: Cloudflare Workers AI
- **Vector DB**: Redis (Upstash)
- **Metadata**: Cloudflare KV
- **Deployment**: Wrangler CLI

Built for simplicity, designed for scale. ğŸš€
